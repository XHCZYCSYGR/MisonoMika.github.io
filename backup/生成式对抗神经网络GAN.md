# 基本概念
## GAN的任务
     顾名思义，我们的目标是生成和输入X类似或具有相同特征的图像、文本等。
## ~~那我问你~~  GAN（Generative Adversarial Networks）与一般的神经网络有什么不同？
   一般的神经网络是“单一”的输入，即tensor[X]，但是GAN的输入是X+Z（类似通信原理的AWGN信道，只不过Z不一定是高斯分布），Z是已知简单分布的采样值（同样转为tensor），不一定和X同维，可以与X做不同的运算，且每次都会更新。然后整体作为输入。我们的目标是让GAN不仅注意到X，会受到Z的影响。
## 如何理解对抗？
     Generator（G）与Discriminator（D）的对抗可以通俗的理解为：捕食者与被捕食者。对抗的过程大致如下：
- G.v1（初始化参数，随机的）对采样得到的Z进行学习，得到输出Y.v1
- 更新D.v1中的参数，使D.v1可以分辨Y.v1与输入X的差别。对D的理解：D的功能可以看作对Y.v1和X进行分类（或打分），D的输出可以是分类的Label（分数）
- 固定D.v1，更新G.v1的参数（Z也会变），使更新后G.v2的输出Y.v2可以“骗过”D.v1，即经D.v1判决或评分后，Y.v2和X没有区别
- 固定G.v2，更新D.v1的参数，使更新后D.v2可以分辨Y.v2和X的区别
- 循环上述步骤得到具有生成的G.vxxx

# GAN的理论支持
## GAN遇到的问题
我们要优化的目标函数：
    
$$
G^* = arg \  \underset{G}{min} \ Div(P_G \  , \  P_{data}) 
$$

其中， $P_G$表示经过Generator输出的Y的分布， $P_{data}$表示X的原始分布，Div是divergence的缩写。也就是说，我们的目标是找到一个最佳的G，使 $P_G$和 $P_{data}$ 的概率分布最为接近。
一般情况下， $Div(P_G \  , \  P_{data})$ 可以是KL散度或JS散度，但是，对于未知的 $P_{data}$，若按照定义式计算，可行性极差（学习途中偶遇超级积分，拼尽全力无法战胜）。
GAN的解决方案：**Sampling is GOOD enough**

## 为什么能够通过Sampling解决问题？
首先，我们回看Discriminator的功能：

$$
D^* = arg \  \underset{D}{max} \  V(D \   , \   G)
$$

其中

$$
V(D \  , \  G) = E_{y \sim P_{data}}[logD(y)] + E_{y \sim P_G}[log(1-D(y))]
$$

从上面的公式不难看出，D的目标是使 $y \sim P_{data}$得到的分数比较高，而让 $y \sim P_G$的分数尽可能低，最后使得D的分辨力足够强大。
也就是说，对D的训练可以看作对一个二元分类问题进行训练。
另外地，经过数学推导，发现 $\underset{D}{max} \  V(D \   , \   G)$和JS散度有关。而在上面的目标函数中， $Div(P_G \  , \  P_{data})$可以是JS散度，所以，目标函数可更新为

$$
G^* = arg \  \underset{G}{min} \ \underset{D}{max} \  V(D \   , \   G) 
$$

补充说明：实际上我们也可以使用其他的 $Div(P_G \  , \  P_{data})$，在使用不同散度时应当使用的公式在有关f-GAN的文章中亦有记载，网址[https://arxiv.org/abs/1606.00709](url)

由此，我们便拥有计算 $Div(P_G \  , \  P_{data})$的方法。

但是，即使我们可以计算 $Div(P_G \  , \  P_{data})$，GAN还是很难train动下面列举两个最常见的原因。

1. 一般情况下， $P_{data}$和 $P_G$在高维空间中的测度较小。以二维平面举例， $P_G$和 $P_{data}$的分布可能就是两条线（平面上大部分点都不属于我们想要的概率分布），这会导致两个分布的重合部分极小（几乎可以忽略不计），最终使D没有改善或修改。
2. 即使两者重合部分可以避免上面的情况，我们也有可能因为sampling过程中的样本数目过少，导致取样点无法充分表示 $P_{data}$和 $P_{G}$的分布。

在上面两种原因的作用下，以使用JS散度为例，可能的实验结果表示为D分辨的正确率为100%，且loss为 $log2$。也就是说，通过loss和D的输出，我们无法判断模型是否真正学到东西，只能通过输出G的图片人眼观察是否有生成效果。（难用o(≧口≦)o）  

## 解决JS散度带来的问题——————Wasserstein distance
Wasserstein distance（瓦瑟斯坦距离），也称为Earth Mover's Distance (EMD)。通俗地来讲，原始分布记为Q，G输出的分布记为P，EMD是将P分布调整为Q所需“距离”的度量。
由此，即使JS散度相同，我们也能通过EMD的数值来了解P和Q是否在接近。换一个角度说，EMD的值可以反应G是否真正在学习。
但是，对于相同的P和Q，调整方案有很多种（对应不同的EMD），我们取最小的作为EMD值，数学公式表达如下：

$$
\underset{D \in 1-Lipschitz}{max}  E_{y \sim P_{data}} [D(y)] - E_{y \sim P_G}[D(y)] 
$$

其中 $D \in 1-Lipschitz$表示D是足够平缓的（smooth enough），由此保证，当 $P_{data}$和 $P_{G}$分布不重叠时，D不会为相应部分分配  $\pm \infty$ ，如下图所示。

![Image](https://github.com/user-attachments/assets/5e56f2ff-2e13-4ae5-9317-a3e242202304)

# GAN如何评价好坏？
通过上面的介绍，我们已经能将GANtrain起来，但是，仅仅观察loss我们是无法评价G的生成效果，下面介绍评价G生成效果的几种方案
## 原始人，起洞！
人工辨别，一眼盯真。
## 现代人
将G生成的输出（图片、文字等）作为一个（图片，文本）分类器的输入，观察分类器的输出（概率分布、类别评分等），如果分类器输出的概率分布比较集中，则说明G的生成效果较好（或准确）。
### 现代人的问题
G可能会出现Mode Collapase（模式崩溃）的问题，即G在生成时为了使分类器的输出“优秀”，可能会反反复复输出同一类图片，进而忽略了原始数据的概率分布（失去多样性），如下图所示。

![Image](https://github.com/user-attachments/assets/9ab85e51-a2fa-4f90-a828-d47f6f0ac609)

通过上面的分析，我们发现，当发生上述情况时，G生成的内容种类非常有限，那么我们就可以通过观察分类器输出类别的平均概率分布 $p(c|y)$，如果平均概率的分布较为集中，表示G生成的内容十分有限，G的生成效果可能很差。

## 三体人——————FID
上面我们说过，我们通过分类器评价G生成的效果，但是可能会产生模式崩溃的问题，究其根本其实是G生成的内容特征过于单一（不同与原始分布）。
那么，我们就可以通过比较G和原始数据的特征相似度来评价模型的好坏，，而恰好我们引入的分类器恰好可以提取输入的特征，FID由此诞生。
FID的步骤（简）：

1. 将G的输出和原始数据通过classifier提取特征，分别记为 $G.l$、 $P.l$（注：数据量较大，一般需要采样）
2. 将 $G.l$、 $P.l$拟合为高斯分布
3. 计算两者的FID

FID计算公式如下：

$$
FID = || \mu_r - \mu_g ||^{2} + Tr( \Sigma _r + \Sigma _g - 2( \Sigma _r \  \Sigma _g)^{\frac{1}{2}} )
$$

其中， $\mu_r$和 $\Sigma_r$分别为真实图像特征的均值和协方差矩阵， $\mu_g$和 $\Sigma_g$分别为生成图像特征的均值和协方差矩阵， $Tr$表示矩阵的迹。
由于FID值表示两个高斯分布之间距离，所以FID值越小，代表 $P_G$和 $P_{data}$越接近。

但是，神也会受伤。FID也有它的问题。G有可能只是“记住”了数据集的分布，而不是生成了类似于数据集的分布。通俗来说，G完成的任务就是查表，即输出和原来的内容相同，没有“生成新内容”的能力。

# DLC1：Conditional GAN
上面我们让GAN生成了和输入X相近分布的内容，在此基础上，我们可以加入一些限制。
例如：

我已经有了一个可以生成不同人脸的GAN，但是我还想得寸进尺，GAN还可以接收文字作为输入，内容为人脸的描述（瞳色、发色、人种等），这样我就得到了一个可以限定输出的GAN。

更进一步，既然可以限定人脸特征，为什么不把人脸也作为特征输入呢？由此文生图的GAN概念已成。

文生图的Conditional GAN结构大致如下：

![Image](https://github.com/user-attachments/assets/e44606da-3d0d-453a-9535-38dba7467e12)

相应的D不能只辨别生成的y是否真实，判断y是否满足x的描述也要进行考虑。

![Image](https://github.com/user-attachments/assets/4879d01a-c9b5-4ce4-9374-7b19b0a9a54d)

上面对于数据集要求略有严格，首先每张图片要有对应的文字描述（特征），另外，D在也要能够辨别出当y不符合X的描述时，生成的y是不好的。

# DLC2：面对Unpaired Data 的解决方案————Cycle GAN

在DLC1中，我们实现了Conditional GAN，但究其根本，上述的GAN都是有“成对”数据的，即数据存在已知特征或对应的标签。那么，在DLC2中，我们要考虑没有成对标签的GAN。

## 什么时候出现“Unpaired”？
首先，我们需要了解一下什么情况下会出现Unpaired Data。风格迁移就是很好的例子。以图片风格迁移为例，想要把现实的照片迁移为二次元风格的图片，我们手中只有两个数据集，分别是现实照片和二次元图片，二者并没有明显的“Paired”关系。

## 如何在“Unpaired Data”情况下设计GAN

我们可以参考DLC的设计，将输入的高斯分布Z变为实际的照片采样，然后输入G.1中进行生成，得到Y.1。对于D.1，我们要做的是让其分辨Y和二次元图片X的区别，对于X给与高分，对于Y.1给与低分。

需要注意的是，由于我们的任务是风格迁移，所以输出的Y需要和现实照片“相像”，所以我们引入第二个G.2，其任务是把G.1生成的Y.1作为输入，生成现实照片风格的图片（Y.2）（类似AE），随后将Y.2与原来的现实照片做比对，将该项评价和D的评分一起作为模型的优化条件。

同样地，我们也可以对Y.1进行同样的操作，Y.1作为输入，通过G.3生成Y.3（现实照片风格的图像，也同样需要对应的D.2），然后将Y.3输入到G.4，生成二次元风格的Y.4，随后将Y.4和Y.1进行比对。

整体的结构见下面的示意图：

![Image](https://github.com/user-attachments/assets/3a615a59-fd86-4d44-af83-77583fd3c49b)

























